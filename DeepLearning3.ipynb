{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0afe6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chisquare, pearsonr, ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, optimizers, metrics\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e95da",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f36f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('firstweek_features_binary.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd20eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Has_location</th>\n",
       "      <th>Has_username</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followees</th>\n",
       "      <th>Age_account</th>\n",
       "      <th>Total_tweets</th>\n",
       "      <th>Favourite</th>\n",
       "      <th>Groups</th>\n",
       "      <th>Has_Image</th>\n",
       "      <th>Aver_favourite</th>\n",
       "      <th>...</th>\n",
       "      <th>Has_tvshow</th>\n",
       "      <th>Posted_noon</th>\n",
       "      <th>Posted_weeke</th>\n",
       "      <th>Posted_eve</th>\n",
       "      <th>Has_excl</th>\n",
       "      <th>Num_hashtag</th>\n",
       "      <th>Opt_len</th>\n",
       "      <th>Has_suggest</th>\n",
       "      <th>Has_video</th>\n",
       "      <th>@@class@@</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39113.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>663748.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4658.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>3201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Has_location  Has_username  Followers  Followees  Age_account  \\\n",
       "0             0             0    39113.0       10.0        421.0   \n",
       "1             0             0   663748.0       28.0       2025.0   \n",
       "2             1             0     1836.0      597.0        242.0   \n",
       "3             0             0     3494.0     4617.0        226.0   \n",
       "4             0             0      523.0      714.0        375.0   \n",
       "\n",
       "   Total_tweets  Favourite  Groups  Has_Image  Aver_favourite  ...  \\\n",
       "0        1221.0      145.0  1489.0          1            0.34  ...   \n",
       "1        4658.0        3.0   631.0          0            0.00  ...   \n",
       "2         272.0        0.0     3.0          0            0.00  ...   \n",
       "3        1548.0      711.0    29.0          0            3.15  ...   \n",
       "4        5715.0     3201.0     1.0          0            8.54  ...   \n",
       "\n",
       "   Has_tvshow  Posted_noon  Posted_weeke  Posted_eve Has_excl  Num_hashtag  \\\n",
       "0           0            0             1           0        0          0.0   \n",
       "1           0            0             1           0        0          0.0   \n",
       "2           0            0             1           1        0          0.0   \n",
       "3           0            0             0           0        0          0.0   \n",
       "4           0            0             1           0        1          0.0   \n",
       "\n",
       "   Opt_len  Has_suggest  Has_video  @@class@@  \n",
       "0        0            0          0          1  \n",
       "1        0            0          0          1  \n",
       "2        0            0          0          1  \n",
       "3        0            0          0          1  \n",
       "4        0            0          0          1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d39104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def calc_ttest(df, pred, resp, values):\n",
    "    assert len(values) == 2\n",
    "    \n",
    "    subset1 = df[df[resp] == values[0]]\n",
    "    subset2 = df[df[resp] == values[1]]\n",
    "    \n",
    "    return ttest_ind(subset1[pred], subset2[pred], equal_var=False)\n",
    "\n",
    "def filter_significant_t(df, cls, alpha):\n",
    "    col_list = []\n",
    "    columns = list(df.columns)\n",
    "    columns.remove(cls)\n",
    "    \n",
    "    for col in columns:\n",
    "        result = calc_ttest(df, col, cls, [0, 1])\n",
    "        \n",
    "        if result.pvalue <= alpha:\n",
    "            col_list.append(col)\n",
    "    \n",
    "    return df[col_list]\n",
    "\n",
    "def calc_chisquare(df, pred, resp, value, silent=False):\n",
    "    subset = df[df[resp] == value]\n",
    "    true_unique, true_counts = np.unique(df[pred], return_counts=True)\n",
    "    \n",
    "    unique, counts = np.unique(subset[pred], return_counts=True)\n",
    "    sample_counts = np.zeros(len(true_counts))\n",
    "    \n",
    "    for attr, count in zip(unique, counts):\n",
    "        pos = np.where(true_unique == attr)[0][0]\n",
    "        sample_counts[pos] = count\n",
    "        \n",
    "    scaled_counts = len(df)*sample_counts/len(subset)\n",
    "    if not silent:\n",
    "        print(scaled_counts)\n",
    "        print(true_counts)\n",
    "    return chisquare(scaled_counts, true_counts)\n",
    "\n",
    "def filter_significant_x2(df, cls, alpha):\n",
    "    col_list = []\n",
    "    columns = list(df.columns)\n",
    "    columns.remove(cls)\n",
    "#     print(columns)\n",
    "    \n",
    "    for col in columns:\n",
    "        result0 = calc_chisquare(df, col, cls, 0, silent=True)\n",
    "        result1 = calc_chisquare(df, col, cls, 1, silent=True)\n",
    "        \n",
    "        if result0.pvalue <= alpha or result1.pvalue <= alpha:\n",
    "            col_list.append(col)\n",
    "    \n",
    "    return df[col_list]\n",
    "\n",
    "def numerify(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    if x == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2522a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['Followers',\n",
    "                 'Followees',\n",
    "                 'Age_account',\n",
    "                 'Total_tweets',\n",
    "                 'Favourite', \n",
    "                 'Groups', \n",
    "                 'Aver_favourite', \n",
    "                 'Length_tweet',\n",
    "                 'Aver_tweets',\n",
    "                 'Name_length',\n",
    "                 '@@class@@']\n",
    "\n",
    "continuous = df[continuous_cols]\n",
    "continuous_cols.remove('@@class@@')\n",
    "discrete = df.drop(continuous_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56566aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_continuous = filter_significant_t(continuous, '@@class@@', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae8e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_discrete = filter_significant_x2(discrete, '@@class@@', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6fc865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Has_location</th>\n",
       "      <th>Has_username</th>\n",
       "      <th>Has_Image</th>\n",
       "      <th>Contain_URL</th>\n",
       "      <th>Sent_level</th>\n",
       "      <th>Has_Uword</th>\n",
       "      <th>Posted_holiday</th>\n",
       "      <th>Has_number</th>\n",
       "      <th>Has_rt</th>\n",
       "      <th>Has_org</th>\n",
       "      <th>Has_tvshow</th>\n",
       "      <th>Posted_noon</th>\n",
       "      <th>Posted_weeke</th>\n",
       "      <th>Posted_eve</th>\n",
       "      <th>Has_excl</th>\n",
       "      <th>Num_hashtag</th>\n",
       "      <th>Opt_len</th>\n",
       "      <th>Has_suggest</th>\n",
       "      <th>Has_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6043136 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Has_location  Has_username  Has_Image  Contain_URL Sent_level  \\\n",
       "0                   0             0          1            1   negative   \n",
       "1                   0             0          0            0   positive   \n",
       "2                   1             0          0            1   negative   \n",
       "3                   0             0          0            1   negative   \n",
       "4                   0             0          0            0   negative   \n",
       "...               ...           ...        ...          ...        ...   \n",
       "6043131             0             0          1            1   positive   \n",
       "6043132             0             0          0            0   positive   \n",
       "6043133             0             0          0            0   negative   \n",
       "6043134             0             0          0            1   negative   \n",
       "6043135             0             0          1            1   negative   \n",
       "\n",
       "         Has_Uword  Posted_holiday  Has_number  Has_rt  Has_org  Has_tvshow  \\\n",
       "0                0               1           0       0        0           0   \n",
       "1                0               1           1       0        0           0   \n",
       "2                0               1           0       0        0           0   \n",
       "3                0               0           0       0        0           0   \n",
       "4                0               1           0       0        0           0   \n",
       "...            ...             ...         ...     ...      ...         ...   \n",
       "6043131          0               0           0       0        0           0   \n",
       "6043132          0               0           1       0        0           0   \n",
       "6043133          0               0           0       0        0           0   \n",
       "6043134          0               0           0       0        0           0   \n",
       "6043135          0               0           0       0        0           0   \n",
       "\n",
       "         Posted_noon  Posted_weeke  Posted_eve  Has_excl  Num_hashtag  \\\n",
       "0                  0             1           0         0          0.0   \n",
       "1                  0             1           0         0          0.0   \n",
       "2                  0             1           1         0          0.0   \n",
       "3                  0             0           0         0          0.0   \n",
       "4                  0             1           0         1          0.0   \n",
       "...              ...           ...         ...       ...          ...   \n",
       "6043131            0             1           0         1          0.0   \n",
       "6043132            0             1           0         1          0.0   \n",
       "6043133            0             1           0         0          0.0   \n",
       "6043134            0             1           0         0          0.0   \n",
       "6043135            0             1           0         0          0.0   \n",
       "\n",
       "         Opt_len  Has_suggest  Has_video  \n",
       "0              0            0          0  \n",
       "1              0            0          0  \n",
       "2              0            0          0  \n",
       "3              0            0          0  \n",
       "4              0            0          0  \n",
       "...          ...          ...        ...  \n",
       "6043131        0            0          0  \n",
       "6043132        1            0          0  \n",
       "6043133        0            0          0  \n",
       "6043134        0            0          0  \n",
       "6043135        0            0          0  \n",
       "\n",
       "[6043136 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4627a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followees</th>\n",
       "      <th>Age_account</th>\n",
       "      <th>Total_tweets</th>\n",
       "      <th>Favourite</th>\n",
       "      <th>Groups</th>\n",
       "      <th>Aver_favourite</th>\n",
       "      <th>Length_tweet</th>\n",
       "      <th>Aver_tweets</th>\n",
       "      <th>Name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39113.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663748.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4658.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1836.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3494.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.85</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>3201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.24</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043131</th>\n",
       "      <td>2.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043132</th>\n",
       "      <td>2087.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>163551.0</td>\n",
       "      <td>249632.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.85</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.73</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043133</th>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043134</th>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043135</th>\n",
       "      <td>31.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>41052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>34.41</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6043136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Followers  Followees  Age_account  Total_tweets  Favourite  Groups  \\\n",
       "0          39113.0       10.0        421.0        1221.0      145.0  1489.0   \n",
       "1         663748.0       28.0       2025.0        4658.0        3.0   631.0   \n",
       "2           1836.0      597.0        242.0         272.0        0.0     3.0   \n",
       "3           3494.0     4617.0        226.0        1548.0      711.0    29.0   \n",
       "4            523.0      714.0        375.0        5715.0     3201.0     1.0   \n",
       "...            ...        ...          ...           ...        ...     ...   \n",
       "6043131        2.0      796.0          8.0          23.0        9.0     0.0   \n",
       "6043132     2087.0      648.0       2451.0      163551.0   249632.0     7.0   \n",
       "6043133       21.0       18.0       1271.0        1677.0       48.0     1.0   \n",
       "6043134        4.0       54.0       1206.0         265.0        1.0     0.0   \n",
       "6043135       31.0       87.0       1193.0       41052.0        0.0     0.0   \n",
       "\n",
       "         Aver_favourite  Length_tweet  Aver_tweets  Name_length  \n",
       "0                  0.34         111.0         2.90         11.0  \n",
       "1                  0.00          45.0         2.30         16.0  \n",
       "2                  0.00         156.0         1.12          6.0  \n",
       "3                  3.15          74.0         6.85         15.0  \n",
       "4                  8.54          42.0        15.24          8.0  \n",
       "...                 ...           ...          ...          ...  \n",
       "6043131            1.13          77.0         2.88          5.0  \n",
       "6043132          101.85          85.0        66.73         13.0  \n",
       "6043133            0.04          44.0         1.32          6.0  \n",
       "6043134            0.00          49.0         0.22         18.0  \n",
       "6043135            0.00         103.0        34.41         10.0  \n",
       "\n",
       "[6043136 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "430d6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_level = significant_discrete['Sent_level'].apply(numerify)\n",
    "significant_discrete.drop('Sent_level', axis=1)\n",
    "significant_discrete = significant_discrete.assign(Sent_level = Sent_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e366fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(significant_discrete['Sent_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849ee0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Has_location</th>\n",
       "      <th>Has_username</th>\n",
       "      <th>Has_Image</th>\n",
       "      <th>Contain_URL</th>\n",
       "      <th>Sent_level</th>\n",
       "      <th>Has_Uword</th>\n",
       "      <th>Posted_holiday</th>\n",
       "      <th>Has_number</th>\n",
       "      <th>Has_rt</th>\n",
       "      <th>Has_org</th>\n",
       "      <th>...</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followees</th>\n",
       "      <th>Age_account</th>\n",
       "      <th>Total_tweets</th>\n",
       "      <th>Favourite</th>\n",
       "      <th>Groups</th>\n",
       "      <th>Aver_favourite</th>\n",
       "      <th>Length_tweet</th>\n",
       "      <th>Aver_tweets</th>\n",
       "      <th>Name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39113.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>663748.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4658.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.85</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>523.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>5715.0</td>\n",
       "      <td>3201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.24</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Has_location  Has_username  Has_Image  Contain_URL  Sent_level  Has_Uword  \\\n",
       "0             0             0          1            1          -1          0   \n",
       "1             0             0          0            0           1          0   \n",
       "2             1             0          0            1          -1          0   \n",
       "3             0             0          0            1          -1          0   \n",
       "4             0             0          0            0          -1          0   \n",
       "\n",
       "   Posted_holiday  Has_number  Has_rt  Has_org  ...  Followers  Followees  \\\n",
       "0               1           0       0        0  ...    39113.0       10.0   \n",
       "1               1           1       0        0  ...   663748.0       28.0   \n",
       "2               1           0       0        0  ...     1836.0      597.0   \n",
       "3               0           0       0        0  ...     3494.0     4617.0   \n",
       "4               1           0       0        0  ...      523.0      714.0   \n",
       "\n",
       "   Age_account  Total_tweets  Favourite  Groups  Aver_favourite  Length_tweet  \\\n",
       "0        421.0        1221.0      145.0  1489.0            0.34         111.0   \n",
       "1       2025.0        4658.0        3.0   631.0            0.00          45.0   \n",
       "2        242.0         272.0        0.0     3.0            0.00         156.0   \n",
       "3        226.0        1548.0      711.0    29.0            3.15          74.0   \n",
       "4        375.0        5715.0     3201.0     1.0            8.54          42.0   \n",
       "\n",
       "   Aver_tweets  Name_length  \n",
       "0         2.90         11.0  \n",
       "1         2.30         16.0  \n",
       "2         1.12          6.0  \n",
       "3         6.85         15.0  \n",
       "4        15.24          8.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant = significant_discrete.join(significant_continuous)\n",
    "significant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97265b46",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf6e4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = significant, df['@@class@@']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14c2e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8413379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4834508, 29)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ebf9b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1208628, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b73c8448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4834508,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d1ff3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1208628,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d77cd9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X.shape[1],)\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40172282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(128, input_shape=input_shape, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(256, input_shape=input_shape, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b308cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = optimizers.Adam(learning_rate),\n",
    "    metrics = [metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d40546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9443/9443 [==============================] - 24s 2ms/step - loss: 31.0590 - binary_accuracy: 0.6703\n",
      "Epoch 2/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.6500 - binary_accuracy: 0.6661\n",
      "Epoch 3/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.6056 - binary_accuracy: 0.6806\n",
      "Epoch 4/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5689 - binary_accuracy: 0.7806\n",
      "Epoch 5/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5838 - binary_accuracy: 0.7823\n",
      "Epoch 6/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5742 - binary_accuracy: 0.7804\n",
      "Epoch 7/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5333 - binary_accuracy: 0.7815\n",
      "Epoch 8/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5357 - binary_accuracy: 0.7786\n",
      "Epoch 9/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5308 - binary_accuracy: 0.7816\n",
      "Epoch 10/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5649 - binary_accuracy: 0.7820\n",
      "Epoch 11/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5350 - binary_accuracy: 0.7810\n",
      "Epoch 12/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5170 - binary_accuracy: 0.7782\n",
      "Epoch 13/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5407 - binary_accuracy: 0.7766\n",
      "Epoch 14/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5298 - binary_accuracy: 0.7813\n",
      "Epoch 15/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5180 - binary_accuracy: 0.7791\n",
      "Epoch 16/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5125 - binary_accuracy: 0.7799\n",
      "Epoch 17/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5135 - binary_accuracy: 0.7795\n",
      "Epoch 18/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5172 - binary_accuracy: 0.7794\n",
      "Epoch 19/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5167 - binary_accuracy: 0.7799\n",
      "Epoch 20/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5566 - binary_accuracy: 0.7771\n",
      "Epoch 21/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5158 - binary_accuracy: 0.7775\n",
      "Epoch 22/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5078 - binary_accuracy: 0.7791\n",
      "Epoch 23/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5141 - binary_accuracy: 0.7782\n",
      "Epoch 24/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5185 - binary_accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5131 - binary_accuracy: 0.7746\n",
      "Epoch 26/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5102 - binary_accuracy: 0.7786\n",
      "Epoch 27/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5181 - binary_accuracy: 0.7775\n",
      "Epoch 28/50\n",
      "9443/9443 [==============================] - 28s 3ms/step - loss: 0.5137 - binary_accuracy: 0.7781\n",
      "Epoch 29/50\n",
      "9443/9443 [==============================] - 27s 3ms/step - loss: 0.5290 - binary_accuracy: 0.7797\n",
      "Epoch 30/50\n",
      "9443/9443 [==============================] - 21s 2ms/step - loss: 0.5079 - binary_accuracy: 0.7780\n",
      "Epoch 31/50\n",
      "9443/9443 [==============================] - 26s 3ms/step - loss: 0.5406 - binary_accuracy: 0.7775\n",
      "Epoch 32/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5084 - binary_accuracy: 0.7787\n",
      "Epoch 33/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5065 - binary_accuracy: 0.7766\n",
      "Epoch 34/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5086 - binary_accuracy: 0.7753\n",
      "Epoch 35/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5050 - binary_accuracy: 0.7743\n",
      "Epoch 36/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5322 - binary_accuracy: 0.7773\n",
      "Epoch 37/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5070 - binary_accuracy: 0.7768\n",
      "Epoch 38/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5048 - binary_accuracy: 0.7765\n",
      "Epoch 39/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5258 - binary_accuracy: 0.7694\n",
      "Epoch 40/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5127 - binary_accuracy: 0.7714\n",
      "Epoch 41/50\n",
      "9443/9443 [==============================] - 38s 4ms/step - loss: 0.5222 - binary_accuracy: 0.7736\n",
      "Epoch 42/50\n",
      "9443/9443 [==============================] - 22s 2ms/step - loss: 0.5412 - binary_accuracy: 0.7687\n",
      "Epoch 43/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5072 - binary_accuracy: 0.7689\n",
      "Epoch 44/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5074 - binary_accuracy: 0.7757\n",
      "Epoch 45/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5146 - binary_accuracy: 0.7763\n",
      "Epoch 46/50\n",
      "9443/9443 [==============================] - 31s 3ms/step - loss: 0.5152 - binary_accuracy: 0.7722\n",
      "Epoch 47/50\n",
      "9443/9443 [==============================] - 29s 3ms/step - loss: 0.5336 - binary_accuracy: 0.7726\n",
      "Epoch 48/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5088 - binary_accuracy: 0.7753\n",
      "Epoch 49/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5027 - binary_accuracy: 0.7770\n",
      "Epoch 50/50\n",
      "9443/9443 [==============================] - 20s 2ms/step - loss: 0.5076 - binary_accuracy: 0.7785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23fcbdc7610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "460ebb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 0.4801 - binary_accuracy: 0.7860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48007869720458984, 0.7859945297241211]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4d47079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9443/9443 [==============================] - 13s 1ms/step - loss: 0.4803 - binary_accuracy: 0.7860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48030444979667664, 0.7860434055328369]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "399f3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Dense(128, input_shape=input_shape, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(256, input_shape=input_shape, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(512, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cd3d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = optimizers.Adam(learning_rate),\n",
    "    metrics = [metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b76d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 30.1005 - binary_accuracy: 0.6922\n",
      "Epoch 2/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5870 - binary_accuracy: 0.7401\n",
      "Epoch 3/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5632 - binary_accuracy: 0.7692\n",
      "Epoch 4/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5508 - binary_accuracy: 0.7740\n",
      "Epoch 5/50\n",
      "9443/9443 [==============================] - 24s 2ms/step - loss: 0.5562 - binary_accuracy: 0.7751\n",
      "Epoch 6/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5568 - binary_accuracy: 0.7756\n",
      "Epoch 7/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5569 - binary_accuracy: 0.7725\n",
      "Epoch 8/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5571 - binary_accuracy: 0.7741\n",
      "Epoch 9/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5462 - binary_accuracy: 0.7761\n",
      "Epoch 10/50\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5769 - binary_accuracy: 0.7764\n",
      "Epoch 11/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5403 - binary_accuracy: 0.7747\n",
      "Epoch 12/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5528 - binary_accuracy: 0.7704\n",
      "Epoch 13/50\n",
      "9443/9443 [==============================] - 24s 2ms/step - loss: 0.5606 - binary_accuracy: 0.7734\n",
      "Epoch 14/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5529 - binary_accuracy: 0.7738\n",
      "Epoch 15/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5439 - binary_accuracy: 0.7692\n",
      "Epoch 16/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5477 - binary_accuracy: 0.7659\n",
      "Epoch 17/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5452 - binary_accuracy: 0.7671\n",
      "Epoch 18/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5503 - binary_accuracy: 0.7701\n",
      "Epoch 19/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5432 - binary_accuracy: 0.7705\n",
      "Epoch 20/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5431 - binary_accuracy: 0.7705\n",
      "Epoch 21/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5493 - binary_accuracy: 0.7643\n",
      "Epoch 22/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5532 - binary_accuracy: 0.7623\n",
      "Epoch 23/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5462 - binary_accuracy: 0.7688\n",
      "Epoch 24/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5481 - binary_accuracy: 0.7649\n",
      "Epoch 25/50\n",
      "9443/9443 [==============================] - 26s 3ms/step - loss: 0.5480 - binary_accuracy: 0.7665\n",
      "Epoch 26/50\n",
      "9443/9443 [==============================] - 28s 3ms/step - loss: 0.5633 - binary_accuracy: 0.7691\n",
      "Epoch 27/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5420 - binary_accuracy: 0.7735\n",
      "Epoch 28/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5574 - binary_accuracy: 0.7748\n",
      "Epoch 29/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5392 - binary_accuracy: 0.7771\n",
      "Epoch 30/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5823 - binary_accuracy: 0.7749\n",
      "Epoch 31/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5472 - binary_accuracy: 0.7717\n",
      "Epoch 32/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5492 - binary_accuracy: 0.7697\n",
      "Epoch 33/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5478 - binary_accuracy: 0.7660\n",
      "Epoch 34/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5452 - binary_accuracy: 0.7661\n",
      "Epoch 35/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5390 - binary_accuracy: 0.7728\n",
      "Epoch 36/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5410 - binary_accuracy: 0.7715\n",
      "Epoch 37/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5448 - binary_accuracy: 0.7720\n",
      "Epoch 38/50\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5660 - binary_accuracy: 0.7683\n",
      "Epoch 39/50\n",
      "9443/9443 [==============================] - 26s 3ms/step - loss: 0.5427 - binary_accuracy: 0.7678\n",
      "Epoch 40/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5687 - binary_accuracy: 0.7678\n",
      "Epoch 41/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5412 - binary_accuracy: 0.7706\n",
      "Epoch 42/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5439 - binary_accuracy: 0.7665\n",
      "Epoch 43/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5410 - binary_accuracy: 0.7701\n",
      "Epoch 44/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5541 - binary_accuracy: 0.7706\n",
      "Epoch 45/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.8821 - binary_accuracy: 0.7718\n",
      "Epoch 46/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5391 - binary_accuracy: 0.7716\n",
      "Epoch 47/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5440 - binary_accuracy: 0.7698\n",
      "Epoch 48/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5451 - binary_accuracy: 0.7691\n",
      "Epoch 49/50\n",
      "9443/9443 [==============================] - 26s 3ms/step - loss: 0.5544 - binary_accuracy: 0.7689\n",
      "Epoch 50/50\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5426 - binary_accuracy: 0.7681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241d101c550>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba3fa9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9443/9443 [==============================] - 23s 2ms/step - loss: 0.5488 - binary_accuracy: 0.7641\n",
      "Epoch 2/10\n",
      "9443/9443 [==============================] - 34s 4ms/step - loss: 0.5479 - binary_accuracy: 0.7629\n",
      "Epoch 3/10\n",
      "9443/9443 [==============================] - 37s 4ms/step - loss: 0.5475 - binary_accuracy: 0.7648\n",
      "Epoch 4/10\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5537 - binary_accuracy: 0.7589\n",
      "Epoch 5/10\n",
      "9443/9443 [==============================] - 35s 4ms/step - loss: 0.5517 - binary_accuracy: 0.7588\n",
      "Epoch 6/10\n",
      "9443/9443 [==============================] - 36s 4ms/step - loss: 0.5493 - binary_accuracy: 0.7633\n",
      "Epoch 7/10\n",
      "9443/9443 [==============================] - 28s 3ms/step - loss: 0.5454 - binary_accuracy: 0.7670\n",
      "Epoch 8/10\n",
      "9443/9443 [==============================] - 27s 3ms/step - loss: 0.5517 - binary_accuracy: 0.7708\n",
      "Epoch 9/10\n",
      "9443/9443 [==============================] - 25s 3ms/step - loss: 0.5461 - binary_accuracy: 0.7699\n",
      "Epoch 10/10\n",
      "9443/9443 [==============================] - 24s 3ms/step - loss: 0.5436 - binary_accuracy: 0.7676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241712321a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "276cdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 3s 1ms/step - loss: 0.5370 - binary_accuracy: 0.7680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5369839072227478, 0.7679749131202698]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7257bde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.venv\\sin\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.venv\\sin\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model2.evaluate(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd4a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDense(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(*args, **kwargs)\n",
    "        self.add = layers.Add()\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        assert inputs.shape[1] == self.dense.units\n",
    "        return self.add([inputs, self.dense(inputs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0140b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 128)               3840      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " residual_dense_18 (Residual  (None, 128)              16512     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_19 (Residual  (None, 128)              16512     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_20 (Residual  (None, 128)              16512     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " residual_dense_21 (Residual  (None, 256)              65792     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_22 (Residual  (None, 256)              65792     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_23 (Residual  (None, 256)              65792     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " residual_dense_24 (Residual  (None, 512)              262656    \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_25 (Residual  (None, 512)              262656    \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " residual_dense_26 (Residual  (None, 512)              262656    \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,204,353\n",
      "Trainable params: 1,204,097\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    layers.Dense(128, input_shape=input_shape, activation=tf.nn.relu),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    ResidualDense(128, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(128, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(128, activation=tf.nn.relu),\n",
    "\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    ResidualDense(256, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(256, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(256, activation=tf.nn.relu),\n",
    "\n",
    "    layers.Dense(512, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    ResidualDense(512, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(512, activation=tf.nn.relu),\n",
    "\n",
    "    ResidualDense(512, activation=tf.nn.relu),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c133684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = optimizers.Adam(learning_rate),\n",
    "    metrics = [metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "190c3628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "9443/9443 [==============================] - 43s 4ms/step - loss: 0.4568 - binary_accuracy: 0.7841\n",
      "Epoch 2/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4340 - binary_accuracy: 0.7954\n",
      "Epoch 3/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4253 - binary_accuracy: 0.8008\n",
      "Epoch 4/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4208 - binary_accuracy: 0.8031\n",
      "Epoch 5/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4179 - binary_accuracy: 0.8045\n",
      "Epoch 6/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4154 - binary_accuracy: 0.8060\n",
      "Epoch 7/80\n",
      "9443/9443 [==============================] - 39s 4ms/step - loss: 0.4128 - binary_accuracy: 0.8074\n",
      "Epoch 8/80\n",
      "9443/9443 [==============================] - 39s 4ms/step - loss: 0.4110 - binary_accuracy: 0.8084\n",
      "Epoch 9/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4105 - binary_accuracy: 0.8088\n",
      "Epoch 10/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4139 - binary_accuracy: 0.8072\n",
      "Epoch 11/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4100 - binary_accuracy: 0.8095\n",
      "Epoch 12/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4076 - binary_accuracy: 0.8109\n",
      "Epoch 13/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4071 - binary_accuracy: 0.8111\n",
      "Epoch 14/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4071 - binary_accuracy: 0.8113\n",
      "Epoch 15/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4062 - binary_accuracy: 0.8115\n",
      "Epoch 16/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4053 - binary_accuracy: 0.8122\n",
      "Epoch 17/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4060 - binary_accuracy: 0.8120\n",
      "Epoch 18/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4044 - binary_accuracy: 0.8127\n",
      "Epoch 19/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4043 - binary_accuracy: 0.8129\n",
      "Epoch 20/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4050 - binary_accuracy: 0.8124\n",
      "Epoch 21/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4051 - binary_accuracy: 0.8125\n",
      "Epoch 22/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4036 - binary_accuracy: 0.8131\n",
      "Epoch 23/80\n",
      "9443/9443 [==============================] - 38s 4ms/step - loss: 0.4046 - binary_accuracy: 0.8126\n",
      "Epoch 24/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4024 - binary_accuracy: 0.8137\n",
      "Epoch 25/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4029 - binary_accuracy: 0.8135\n",
      "Epoch 26/80\n",
      "9443/9443 [==============================] - 46s 5ms/step - loss: 0.4054 - binary_accuracy: 0.8121\n",
      "Epoch 27/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4016 - binary_accuracy: 0.8141\n",
      "Epoch 28/80\n",
      "9443/9443 [==============================] - 49s 5ms/step - loss: 0.4011 - binary_accuracy: 0.8144\n",
      "Epoch 29/80\n",
      "9443/9443 [==============================] - 50s 5ms/step - loss: 0.4035 - binary_accuracy: 0.8133\n",
      "Epoch 30/80\n",
      "9443/9443 [==============================] - 51s 5ms/step - loss: 0.4027 - binary_accuracy: 0.8137\n",
      "Epoch 31/80\n",
      "9443/9443 [==============================] - 49s 5ms/step - loss: 0.4024 - binary_accuracy: 0.8138\n",
      "Epoch 32/80\n",
      "9443/9443 [==============================] - 48s 5ms/step - loss: 0.4010 - binary_accuracy: 0.8145\n",
      "Epoch 33/80\n",
      "9443/9443 [==============================] - 46s 5ms/step - loss: 0.4021 - binary_accuracy: 0.8140\n",
      "Epoch 34/80\n",
      "9443/9443 [==============================] - 47s 5ms/step - loss: 0.4005 - binary_accuracy: 0.8147\n",
      "Epoch 35/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4006 - binary_accuracy: 0.8149\n",
      "Epoch 36/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4026 - binary_accuracy: 0.8138\n",
      "Epoch 37/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4017 - binary_accuracy: 0.8143\n",
      "Epoch 38/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4000 - binary_accuracy: 0.8152\n",
      "Epoch 39/80\n",
      "9443/9443 [==============================] - 46s 5ms/step - loss: 0.4017 - binary_accuracy: 0.8144\n",
      "Epoch 40/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4084 - binary_accuracy: 0.8102\n",
      "Epoch 41/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4066 - binary_accuracy: 0.8117\n",
      "Epoch 42/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4041 - binary_accuracy: 0.8129\n",
      "Epoch 43/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4043 - binary_accuracy: 0.8127\n",
      "Epoch 44/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4060 - binary_accuracy: 0.8122\n",
      "Epoch 45/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4049 - binary_accuracy: 0.8127\n",
      "Epoch 46/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4058 - binary_accuracy: 0.8122\n",
      "Epoch 47/80\n",
      "9443/9443 [==============================] - 46s 5ms/step - loss: 0.4047 - binary_accuracy: 0.8127\n",
      "Epoch 48/80\n",
      "9443/9443 [==============================] - 46s 5ms/step - loss: 0.4026 - binary_accuracy: 0.8141\n",
      "Epoch 49/80\n",
      "9443/9443 [==============================] - 47s 5ms/step - loss: 0.4049 - binary_accuracy: 0.8126\n",
      "Epoch 50/80\n",
      "9443/9443 [==============================] - 53s 6ms/step - loss: 0.4040 - binary_accuracy: 0.8132\n",
      "Epoch 51/80\n",
      "9443/9443 [==============================] - 50s 5ms/step - loss: 0.4036 - binary_accuracy: 0.8134\n",
      "Epoch 52/80\n",
      "9443/9443 [==============================] - 49s 5ms/step - loss: 0.4041 - binary_accuracy: 0.8131\n",
      "Epoch 53/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4035 - binary_accuracy: 0.8135\n",
      "Epoch 54/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4215 - binary_accuracy: 0.8037\n",
      "Epoch 55/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4171 - binary_accuracy: 0.8062\n",
      "Epoch 56/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4175 - binary_accuracy: 0.8057\n",
      "Epoch 57/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4106 - binary_accuracy: 0.8096\n",
      "Epoch 58/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4139 - binary_accuracy: 0.8076\n",
      "Epoch 59/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4127 - binary_accuracy: 0.8084\n",
      "Epoch 60/80\n",
      "9443/9443 [==============================] - 40s 4ms/step - loss: 0.4117 - binary_accuracy: 0.8086\n",
      "Epoch 61/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4143 - binary_accuracy: 0.8072\n",
      "Epoch 62/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4095 - binary_accuracy: 0.8093\n",
      "Epoch 63/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4086 - binary_accuracy: 0.8098\n",
      "Epoch 64/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4112 - binary_accuracy: 0.8085\n",
      "Epoch 65/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4177 - binary_accuracy: 0.8056\n",
      "Epoch 66/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4114 - binary_accuracy: 0.8088\n",
      "Epoch 67/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4131 - binary_accuracy: 0.8082\n",
      "Epoch 68/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4130 - binary_accuracy: 0.8081\n",
      "Epoch 69/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4122 - binary_accuracy: 0.8084\n",
      "Epoch 70/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4144 - binary_accuracy: 0.8071\n",
      "Epoch 71/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4103 - binary_accuracy: 0.8091\n",
      "Epoch 72/80\n",
      "9443/9443 [==============================] - 41s 4ms/step - loss: 0.4127 - binary_accuracy: 0.8080\n",
      "Epoch 73/80\n",
      "9443/9443 [==============================] - 45s 5ms/step - loss: 0.4141 - binary_accuracy: 0.8067\n",
      "Epoch 74/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4106 - binary_accuracy: 0.8089\n",
      "Epoch 75/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4096 - binary_accuracy: 0.8093\n",
      "Epoch 76/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4077 - binary_accuracy: 0.8103\n",
      "Epoch 77/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4074 - binary_accuracy: 0.8103\n",
      "Epoch 78/80\n",
      "9443/9443 [==============================] - 42s 4ms/step - loss: 0.4068 - binary_accuracy: 0.8105\n",
      "Epoch 79/80\n",
      "9443/9443 [==============================] - 44s 5ms/step - loss: 0.4121 - binary_accuracy: 0.8083\n",
      "Epoch 80/80\n",
      "9443/9443 [==============================] - 43s 5ms/step - loss: 0.4094 - binary_accuracy: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27f508e6560>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, epochs=80, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46e0d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361/2361 [==============================] - 7s 2ms/step - loss: 0.4788 - binary_accuracy: 0.7218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4787660539150238, 0.7217729687690735]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51f29f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37770/37770 [==============================] - 54s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b37edbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1208628, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.round(tf.nn.sigmoid(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2139fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28072b00550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, tf.round(tf.nn.sigmoid(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d175500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
